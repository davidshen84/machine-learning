{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Machine Learning Online Class - Exercise 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from numpy import (eye, loadtxt, hstack, zeros, ones, dot, transpose, array, linspace, logspace,\n",
    "                   meshgrid, float64, log, finfo, exp, mean, double)\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import plot, ylabel, xlabel, figure, subplots, contour, legend, axis, contour\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = loadtxt('ex2data1.txt', dtype=float64, delimiter=',')\n",
    "X, y = data[:, :2], data[:, -1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 1: Plotting\n",
    "\n",
    "We start the exercise by first plotting the data to understand the the problem we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot2_data(X, y, data_labels, axis_labels):\n",
    "    pos = y[:, 0] == 1\n",
    "    neg = y[:, 0] == 0\n",
    "\n",
    "    plot(X[pos, 0], X[pos, 1], 'k+', label=data_labels[0],\n",
    "       markerfacecolor='b', markersize=7)\n",
    "    plot(X[neg, 0], X[neg, 1], 'ko', label=data_labels[1],\n",
    "       markerfacecolor='Y', markersize=7)\n",
    "\n",
    "    # Put some labels\n",
    "    if axis_labels and len(axis_labels) > 1:\n",
    "        xlabel(axis_labels[0])\n",
    "        ylabel(axis_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data with `+` indicating (y = 1) examples and `o` indicating (y = 0) examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot2_data(X, y,\n",
    "          ['Admitted', 'Not Admitted'],\n",
    "          ['Exam 1', 'Exam 2'])\n",
    "legend(numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 2: Compute Cost and Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eps = finfo(float64).eps\n",
    "# eps = 1e-5\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1. / (1. + exp(-z))\n",
    "\n",
    "def cost_function(theta, X, y):\n",
    "    \"\"\"cost function\"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    theta = theta.reshape(n, 1)\n",
    "\n",
    "    h_theta = sigmoid(X.dot(theta))\n",
    "    h_theta[h_theta < eps] = eps\n",
    "    h_theta[(1 - eps < h_theta) & (h_theta < 1 + eps)] = 1 - eps\n",
    "    J = (- y.T.dot(log(h_theta)) - (1. - y).T.dot(log(1. - h_theta))) / m\n",
    "    grad = X.T.dot(h_theta - y) / m\n",
    "\n",
    "    return J[0, 0], grad.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "m, n = X.shape\n",
    "\n",
    "# Initialize fitting parameters\n",
    "initial_theta = zeros((n + 1, 1))\n",
    "\n",
    "\n",
    "# Add intercept term to x and X_test\n",
    "X = hstack((ones((m, 1)), X))\n",
    "\n",
    "# Compute and display initial cost and gradient\n",
    "cost, grad = cost_function(initial_theta, X, y)\n",
    "print(f'''Cost at initial theta (zeros): {cost}\n",
    "Gradient at initial theta (zeros): {grad}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 3: Optimizing using *minimize*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(theta, X, y, *args):\n",
    "\n",
    "    # Plot Data\n",
    "    plot2_data(X[:, 1:3], y, *args)\n",
    "\n",
    "    n = X.shape[1]\n",
    "\n",
    "    if n <= 3:\n",
    "        # Only need 2 points to define a line, so choose two endpoints\n",
    "        plot_x = array([min(X[:, 1]) - 2, max(X[:, 1]) + 2])\n",
    "\n",
    "        # Calculate the decision boundary line\n",
    "        plot_y = (-1 / theta[2]) * (theta[1] * plot_x + theta[0])\n",
    "\n",
    "        # Plot, and adjust axes for better viewing\n",
    "        plot(plot_x, plot_y, label='Decision Boundary')\n",
    "\n",
    "        # Legend, specific for the exercise\n",
    "        axis([30, 100, 30, 100])\n",
    "    else:\n",
    "        # Here is the grid range\n",
    "        u = linspace(-1, 1.5, 50) \n",
    "        v = linspace(-1, 1.5, 50)\n",
    "        size = u.size\n",
    "        z = zeros((size, size))\n",
    "        # Evaluate z = theta*x over the grid\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                z[i, j] = map_feature(u[i], v[j]).dot(theta)\n",
    "\n",
    "        z = z.T\n",
    "        contour(u, v, z, [0, 0], linewidth=2, label='Decision Boundary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result = minimize(cost_function,\n",
    "                  initial_theta,\n",
    "                  args=(X, y),\n",
    "                  method='BFGS',\n",
    "                  jac=True,\n",
    "                  options=dict(maxiter=400))\n",
    "cost = result.fun\n",
    "theta = result.x\n",
    "\n",
    "print(f'''Cost at theta found by minimize: {cost}\n",
    "theta: {theta}''')\n",
    "\n",
    "plot_decision_boundary(theta, X, y,\n",
    "                       ['Admitted', 'Not Admitted'],\n",
    "                       ['Exam 1', 'Exam 2'])\n",
    "legend(numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Predict and Accuracies\n",
    "\n",
    "After learning the parameters, you'll like to use it to predict the\n",
    "outcomes on unseen data. In this part, you will use the logistic\n",
    "regression model to predict the probability that a student with score\n",
    "45 on exam 1 and score 85 on exam 2 will be admitted.\n",
    "\n",
    "Furthermore, you will compute the training and test set accuracies of\n",
    "our model.\n",
    "\n",
    "Your task is to complete the code in predict.m\n",
    "\n",
    "Predict probability for a student with score 45 on exam 1 and score 85\n",
    "on exam 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob = sigmoid(array([1, 45, 85]).dot(theta))\n",
    "print(f'''For a student with scores 45 and 85, we predict an admission probability of {prob}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy on our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    return (sigmoid(X.dot(theta)) >= 0.5).reshape((-1, 1))\n",
    "\n",
    "p = predict(theta, X)\n",
    "print(f'Train Accuracy: { mean(double(p == y)) * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
