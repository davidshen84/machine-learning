{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exercise 5 | Regularized Linear Regression and Bias-Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 1: Loading and Visualizing Data\n",
    "\n",
    "We start the exercise by first loading and visualizing the\n",
    "dataset. The following code will load the dataset into your\n",
    "environment and plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loading and Visualizing Data ...\n",
    "\n",
    "data1 = loadmat('ex5data1.mat')\n",
    "\n",
    "X = data1['X']\n",
    "Xtest = data1['Xtest']\n",
    "Xval = data1['Xval']\n",
    "y = data1['y']\n",
    "ytest = data1['ytest']\n",
    "yval = data1['yval']\n",
    "\n",
    "m = X.shape[0]\n",
    "\n",
    "plt.plot(X, y, 'rx', markersize=10, linewidth=1.5)\n",
    "plt.xlabel('Change in water level (x)')\n",
    "plt.ylabel('Water flowing out of the dam (y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 2: Regularized Linear Regression Cost\n",
    "\n",
    "You should now implement the cost function for regularized linear\n",
    "regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def linear_reg_cost_function(theta, X, y, lambda_):\n",
    "    \"\"\"Compute cost and gradient for regularized linear regression with multiple variables.\"\"\"\n",
    "\n",
    "    m = len(y)\n",
    "    theta = theta.reshape(X.shape[1], 1)\n",
    "\n",
    "    temp = X.dot(theta) - y\n",
    "    J = (temp.T.dot(temp)) / (2 * m) + lambda_ / (2 * m) * np.sum(theta[1:] ** 2)\n",
    "\n",
    "    grad = X.T.dot(temp) / m\n",
    "    grad[1:] += lambda_ / m * theta[1:]\n",
    "\n",
    "    return J, grad.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta = np.array([1, 1]).reshape((2, 1))\n",
    "J, _ = linear_reg_cost_function(theta, np.c_[np.ones((m, 1)), X], y, 1)\n",
    "\n",
    "print(f'''Cost at theta = [1 ; 1]: {J}\n",
    "(this value should be about 303.993192)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part 3: Regularized Linear Regression Gradient\n",
    "\n",
    "You should now implement the gradient for regularized linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = np.array([1, 1]).reshape((2, 1))\n",
    "J, grad = linear_reg_cost_function(theta, np.c_[np.ones((m, 1)), X], y, 1)\n",
    "\n",
    "print(f'''Gradient at theta = [1 ; 1]:  [{grad[0]}; {grad[1]}]\n",
    "(this value should be about [-15.303016; 598.250744])''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Train Linear Regression\n",
    "\n",
    "Once you have implemented the cost and gradient correctly, the\n",
    "trainLinearReg function will use your cost function to train\n",
    "regularized linear regression.\n",
    "\n",
    "Write Up Note: The data is non-linear, so this will not give a great fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_linear_reg(X, y, lambda_):\n",
    "    \"\"\"Trains linear regression given a dataset (X, y) and a regularization parameter lambda.\"\"\"\n",
    "    \n",
    "    initial_theta = np.zeros((X.shape[1], 1))\n",
    "    result = minimize(linear_reg_cost_function,\n",
    "                      initial_theta,\n",
    "                      args=(X, y, lambda_),\n",
    "                      method='CG',\n",
    "                      jac=True,\n",
    "                      options=dict(maxiter=200))\n",
    "    \n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train linear regression with lambda = 0\n",
    "lambda_ = 0\n",
    "theta = train_linear_reg(np.c_[np.ones((m, 1)), X], y, lambda_)\n",
    "\n",
    "# Plot fit over the data\n",
    "plt.plot(X, y, 'rx', markersize=10, linewidth=1.5)\n",
    "plt.xlabel('Change in water level (x)')\n",
    "plt.ylabel('Water flowing out of the dam (y)')\n",
    "plt.plot(X, np.c_[np.ones((m, 1)), X].dot(theta), '--', linewidth=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
