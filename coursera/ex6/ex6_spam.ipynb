{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 | Spam Classification with SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk import tokenize, stem\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import minimize\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Email Preprocessing\n",
    "\n",
    "To use an SVM to classify emails into Spam v.s. Non-Spam, you first\n",
    "need to convert each email into a vector of features. In this part,\n",
    "you will implement the preprocessing steps for each email. You should\n",
    "complete the code in processEmail.m to produce a word indices vector\n",
    "for a given email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_list():\n",
    "    with open('vocab.txt') as f:\n",
    "        vocab_list = dict([(int(i), j)\n",
    "                           for l in f.readlines()\n",
    "                           for i, j in [l.strip().split('\\t')]])\n",
    "    return vocab_list\n",
    "\n",
    "def process_email(file_contents):\n",
    "    vocab_list = get_vocab_list()\n",
    "    rev_vocab_list = {v : k for k, v in vocab_list.items()}\n",
    "    \n",
    "    # preprocess email\n",
    "    \n",
    "    # lower case\n",
    "    email_contents = file_contents.lower()\n",
    "    \n",
    "    # strip all HTML\n",
    "    email_contents = re.sub(r'<[^<>]+>', ' ', email_contents)\n",
    "    \n",
    "    # handle numbers\n",
    "    email_contents = re.sub(r'[0-9]+', 'number', email_contents)\n",
    "    \n",
    "    # handle URLs\n",
    "    email_contents = re.sub(r'(http|https)://[^\\s]*', 'httpaddr', email_contents)\n",
    "    \n",
    "    # handle email addresses\n",
    "    email_contents = re.sub(r'[^\\s]+@[^\\s]+', 'emailaddr', email_contents)\n",
    "    \n",
    "    # handle $ sign\n",
    "    email_contents = re.sub(r'[$]+', 'dollar', email_contents)\n",
    "    \n",
    "    # tokenize email\n",
    "    strs = tokenize.word_tokenize(email_contents)\n",
    "    \n",
    "    # stem words\n",
    "    stemmer = stem.PorterStemmer()\n",
    "    strs = [stemmer.stem(v) for v in strs]\n",
    "    # get rid of puctuation\n",
    "    strs = [s.strip(' @$/#.-:&*+=[]?!(){},''\">_<;%') for s in strs if s not in ' @$/#.-:&*+=[]?!(){},''\">_<;%']\n",
    "    \n",
    "    print(f'''\n",
    "Processed Email\n",
    "===============\n",
    "{' '.join(strs)}\n",
    "===============''')\n",
    "    return [rev_vocab_list[w] for w in strs if w in rev_vocab_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing sample email (emailSample1.txt)\n",
    "\n",
    "with open('emailSample1.txt') as f:\n",
    "    file_contents = f.read()\n",
    "\n",
    "word_indices = process_email(file_contents)\n",
    "print(f'''\n",
    "Word Indices:\n",
    "\n",
    "{word_indices}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Extraction\n",
    "\n",
    "Now, you will convert each email into a vector of features in R^n. You\n",
    "should complete the code in emailFeatures.m to produce a feature\n",
    "vector for a given email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def email_features(word_indices, vocab_size):\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[word_indices] = 1\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from sample email (emailSample1.txt)\n",
    "\n",
    "vocab_list = get_vocab_list()\n",
    "features = email_features(word_indices, len(vocab_list))\n",
    "\n",
    "print(f'''Length of feature vector: {len(features)}\n",
    "Number of non-zeor entries: {int(np.sum(features))}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Train Linear SVM for Spam Classification\n",
    "\n",
    "In this section, you will train a linear classifier to determine if an\n",
    "email is Spam or Not-Spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the spam email dataset\n",
    "mat = loadmat('spamTrain.mat')\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "\n",
    "# training Linear SVM (Spam Classification)\n",
    "C = 0.1\n",
    "model = svm.LinearSVC(C=C).fit(X, y.ravel())\n",
    "\n",
    "p = model.predict(X)\n",
    "print(f'Training Accuracy: {np.mean(p == y.ravel()) * 100:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Test Spam Classification\n",
    "\n",
    "After training the classifier, we can evaluate it on a test set. We\n",
    "have included a test set in spamTest.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test dataset\n",
    "mat = loadmat('spamTest.mat')\n",
    "Xtest = mat['Xtest']\n",
    "ytest = mat['ytest']\n",
    "\n",
    "# evaluate the trained Linear SVM on a test set\n",
    "p = model.predict(Xtest)\n",
    "print(f'''Test Accuracy: {np.mean(p == ytest.ravel()) * 100:.4}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Top Predictors of Spam\n",
    "\n",
    "Since the model we are training is a linear SVM, we can inspect the\n",
    "weights learned by the model to understand better how it is\n",
    "determining whether an email is spam or not. The following code finds\n",
    "the words with the highest weights in the classifier. Informally, the\n",
    "classifier 'thinks' that these words are the most likely indicators of\n",
    "spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.coef_.ravel()\n",
    "# sort the weights in descending order\n",
    "idx = np.argsort(weights)[::-1]\n",
    "\n",
    "print('Top predictors os spam:')\n",
    "for i in range(15):\n",
    "    print(f'{vocab_list[idx[i]+1]:15}{weights[idx[i]]:.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Try Your Own Emails\n",
    "\n",
    "Now that you've trained the spam classifier, you can use it on your\n",
    "own emails! In the starter code, we have included spamSample1.txt,\n",
    "spamSample2.txt, emailSample1.txt and emailSample2.txt as examples.\n",
    "The following code reads in one of these emails and then uses your\n",
    "learned SVM classifier to determine whether the email is Spam or Not\n",
    "Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'spamSample1.txt'\n",
    "\n",
    "with open(filename) as f:\n",
    "    file_contents = f.read()\n",
    "    \n",
    "word_indices = process_email(file_contents)\n",
    "x = email_features(word_indices, len(vocab_list))\n",
    "p = model.predict(x.reshape(1, -1))\n",
    "\n",
    "print(f'''\n",
    "Processed {filename}\n",
    "Spam Classification: {p}\n",
    "(1 indicates spam, 0 indicates not spam)\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
